---
layout: center
---
# Пересемплирование

---

# Что такое пересемплирование?

#### Это отбор образцов из выборки (как правило, многократный, с заменой)
<br>

#### Виды:
 * **Валидация** и **Валидация**+**Тест**
 * **Кросс-валидация** (CV) используется для
    * **выбора** лучшей модели или поиска ее **гиперпараметров**, а затем
    * для **оценки** ошибки **обобщения** (**тестовой** ошибки)
      * или оценки некоторой меры качества модели ($R^2$, ...)
 * **Bootstrap** используется для
   * анализа **распределения** некоторой *выборочной статистики*
     * Среднее значение, медиана, процентили, дисперсия, $p$-значение, доверительный интервал (CI), параметры модели и т.д.

---

# Что такое пересемплирование?

* Каждое наблюдение участвует в обучении/тестировании модели много раз
  * В CV наблюдения используются $k=5$ или $10$ раз и до $n$ раз
  * Мы повторно подгоняем новую модель или новый набор гиперпараметров $k$ раз
 
 * В бутстрапе наблюдения могут быть использованы $B\sim$ тысячи раз
   * Мы повторно вычисляем рассматриваемую статистику $B$ раз на каждой подвыборке

* Повторная выборка требует больших вычислительных затрат, но может быть распараллелена

---

# Валидационный подход

* Мы **разбиваем** исходную выборку размером $n$ на $2$ подвыборки:
  * **Обучающая**, размером $n_\tau$, используемое для обучения модели
    * На которой модель находит истинные связи между входами и выходами (I/O)
  * **Валидационная** - используется для оценки работы модели на тестовых данных
* При этом "**тестовая ошибка**" - это теоретическая концепция, которая известна только в том случае, если:
  * мы знаем **полную совокупность** наблюдений
  * мы **симулировали** наблюдения и знаем базовое распределение
* Разделение на обучающую/тестовую выборки может быть<br> $80/20$, $70/30$, $60/40$, $50/50$ (в $\%$ от исходной выборки)

<InlineSvg src="/Lecture_5_train_val.svg" height="40px"/>

---

# Перемешивание и предположение об i.i.d.

* Если наблюдения действительно независимы, мы можем разделить выборку как угодно
  * Однако большинство реальных наблюдений имеют некоторую зависимость.
  * Например, собранные за определенное время, случайно упорядоченные по какому-то столбцу, сгруппированные по категориям и т.д.
* Чтобы модель не подстраивалась под локальные зависимости, **перемешивайте наблюдения перед разбиением**!
  * Это помогает **разрушить зависимость между соседними наблюдениями**, которые могут быть связаны между собой
* Некоторые модели хорошо подходят для использования этих локальных эффектов.
  * Например, модели временных рядов могут использовать автокорреляции и сезонные эффекты

---

# Валидационный+Тестовый подход 

* **Большая** выборка может быть разделена на следующие подвыборки:
  * **Обучающую**: для подгонки наших моделей или одной модели с разными гиперпараметрами
  * **Валидационную**: для выбора лучшей модели
    * Мы оцениваем семейство моделей (регрессионные, kNN, ...), гиперпараметры, признаки, преобразования, ...
  * **Тестовую**: для оценки ошибки обобщения или итоговой ошибки
    * Использование только валидационного набора необъективно, так как мы уже знаем, что лучшая модель показала хорошие результаты
* Разделение зависит от конкретного случая, но может составлять $50/25/25$

---

# Смещение, дисперсия и сложность модели

<div class="grid grid-cols-[8fr_5fr]">
<div style="font-size: 90%">

#### **Цели**:
1. **выбрать** модель, которая хорошо обобщает
    * т.е. дает малую ошибку на новых наблюдениях
    * Выполняется на **валидационной** выборке
2. **измерить** ее качество (в виде ошибки или точности)
    * Выполняется на **тестовой** выборке

<br>

* Более сложные модели приводят к переобучению<br> (высокое смещение и низкая дисперсия)
  * Сложность модели коррелирует с количеством степеней свободы и количеством оцениваемых параметров

</div>
<div>
<br>
<figure>
<img src="/Train_Validation_Test.svg" style="width: 430px !important">
</figure>
<br>
  <figure>
    <img src="/ESL_figure_7.1.png" style="width: 370px !important">
    <figcaption style="color:#b3b3b3ff; font-size: 11px;">Источник изображения:
      <a href="https://hastie.su.domains/ElemStatLearn/printings/ESLII_print12.pdf#page=239">ESL Fig. 7.1</a>
    </figcaption>
  </figure>
</div>
</div>
<div style="font-size: 90%">

* Для фиксированной модели ошибка предсказания зависит от обучающего набора наблюдений
</div>

---

# Кросс-валидация (CV)

* В $k$CV мы разбиваем набор наблюдений на $k$ разбиений
  * Каждое разбиение используется как валидационное ($\mathrm{vMSE}_{d,i}$),<br>остальные $k-1$ разбиений используются в обучении
 * Каждый обучающий набор содержит $n_k \approx (k-1)/k$ наблюдений
* $k=5$ и до $10$ - разумный баланс между $1$CV и $n$CV

<div class="grid grid-cols-2 gap-10">
<div>

* Оценка качества CV с $k$ разбиениями:
<br> $\mathrm{CV}_{d,k} := \frac{1}{k}\sum\limits_{i=1}^{k}{\mathrm{vMSE}_{d,i}}$
</div>
<div>
  <br>
  <img src="/ISLRv2_figure_5.5.png" style="width: 550px;">
</div>
</div>

---

# (Не)правильный способ использования CV
<div style="font-size: 92%">

* <span style="color:red">**Неправильный**</span>:
  * Допустим, у нас есть $X_{N \times 1M}$ и мы делаем следующее:
     1. Находим наиболее объясняющие признаки $\tilde{X}_{N \times 100}$
     2. Применяем классификатор, используя $\tilde{X}$
     3. Используем CV для поиска гиперпараметров и оценки ошибки тестирования
  * Проблема в том, что для выбора признаков мы использовали **ВСЕ** наблюдения (обучающие и тестовые)

* <span style="color:green">**Правильный**</span>:
  * Выберем k разбиений и сделаем CV:
     1. Найдем наиболее объясняющие признаки $\tilde{X}_{N \times 100}$
     2. Построим классификатор, используя $\tilde{X}$
     3. Оценим ошибку тестовой выборки
</div>

---

# Bootstrap

### Используется для оценки неопределенности или распределения параметров модели
<br>

### Минимальный пример: рассмотрим выборку $x = {1,2,3,4}$
* Мы можем вычислить:
  * $\bar{x} = 2.5$ - среднее значение
  * $s_x \approx 1.29$ - дисперсия
  * $s_{\bar{x}} = \frac{s_x}{\sqrt{n}} \approx 0.65$ - [стандартная ошибка](https://en.wikipedia.org/wiki/Standard_error) среднего значения

* Каково распределение $\bar{x}$?
  * Мы не можем оценить распределение, потому что у нас есть только одно наблюдение

---

# Bootstrap

* Каково распределение $\bar{x}$?
  * Статистическая теория утверждает, что $\bar{x}$ приближается к гауссовскому со средним $\bar{x}$ и средним отклонением $s_{\bar{x}}$
    * Во многих сложных ситуациях теория не может оценить распределение параметров и оценок
* Мы можем использовать **повторную выборку / пересемплирование**:<br> сгенерировав $B$ бутстрап-выборок $z^{*1}, ..., z^{*B}$
  * Вычислим среднее, $\hat{\mu}^{*i}$, для каждого $z^{*i}$
  * Изучим распределение этих бутстрап-средних

---

# Bootstrap

* Бутстрапинг - это повторная выборка с заменой
  * Она помогает оценить распределение оценок, которые в противном случае наблюдались бы только один раз
* Мы берем $B$ бутстрап-выборок, $\{\bm{Z}^{\ast b}\}_{1:B}$ из $\bm{Z} = \{z_i\}_{1:N}$, $z_i := (x_i, y_i)$
* Пусть $S(\bm{Z})$ - любая интересующая нас статистика ($\mathbb{E}z$, $\mathbb{V}z$, $\hat{y}$, $\beta$, ...)
<div class="grid grid-cols-[2fr_2fr]">
<div>

* С помощью бутстрап-выборок мы можем оценить распределение $S(\bm{Z})$<br>
$\hat{\mathbb{V}}S(\bm{Z}) := \frac{1}{B - 1} \sum\limits_{b=1}^B \big[S(\bm{Z}^{\ast b}) - \bar{S}^2 \big]^2$

</div>
<div>
    <figure>
    <img src="/ESL_figure_7.12.png" style="width: 370px !important">
    <figcaption style="color:#b3b3b3ff; font-size: 11px;">Источник изображения:
      <a href="https://hastie.su.domains/ElemStatLearn/printings/ESLII_print12.pdf#page=269">ESL Fig. 7.12</a>
    </figcaption>
  </figure>
</div>
</div>

---

# Пример Bootstrap

```python {3|4-7|8-11|12-15|17-20|all}
import numpy as np 
np.random.seed(1) 
x = [1,2,3,4] # исходная выборка

B, n = 10, len(x) # число бутстрап-образцов и их размер
bootstrap = lambda x, n=len(x): np.random.choice(x, n) 
z = np.array(bootstrap(x, n*B)).reshape((B,n))
# z = np.array([bootstrap(x) for i in range(B)]) # медленее
z
>> array([[2, 4, 1, 1], [4, 2, 4, 2], [4, 1, 1, 2], [1, 4, 2, 1], [3, 2, 3, 1], \
[3, 2, 3, 1], [4, 1, 3, 1], [2, 3, 3, 1], [4, 4, 2, 2], [4, 3, 1, 3]])

mu = np.mean(z, axis=1) # вычисление среднего значения для каждого образца
mu
>> array([2. , 3. , 2. , 2. , 2.25, 2.25, 2.25, 2.25, 3. , 2.75])

# Вычислим стандартную ошибку бутстрапа, 
# т.е. оценим стандартную ошибку распределения средних
np.std(mu, ddof=1) # число степеней свободы (ddof) = 1 для стандартного отклонения образца
>> 0.395
```

---

# Пример Bootstrap. Увеличение числа образцов

* $\mathrm{Std.Dev.}(Z^{*} | B = 1000) \approx 0.5532$
* $\mathrm{Std.Dev.}(Z^{*} | B = 10000) \approx 0.5608$
* $\mathrm{Std.Dev.}(Z^{*} | B = 100000) \approx 0.5585$

```python {all}
import pandas as pd 
df = pd.DataFrame(mu) 
df.plot(kind='hist', grid=True, title='Histogram of Bootstrap Means'); 
df.describe().round(2).T
```

<div class="flex">
  <div class="flex-grow">
  	<img src="/Bootstrap_1.png" style="width: 300px;">
  </div>
  <div class="flex-grow">
	<img src="/Bootstrap_2.png" style="width: 320px;">
  </div>
</div>

---

# Использование SKLearn для пересемплирования

<div class="grid grid-cols-2">
<div>

* Scikit-Learn имеет удобный набор инструментов для разделения выборки
  * Некоторые из них позволяют также перемешивать события
</div>
<div>
	<img src="/Scikit_learn_splitting_tools.png" style="width: 550px;">
</div>
</div>