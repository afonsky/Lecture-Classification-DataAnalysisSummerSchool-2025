# Примеры классификации

<v-clicks>

1. В отделение неотложной помощи поступает пациент с набором симптомов, которые могут быть отнесены к одному из трех медицинских заболеваний. Какое из этих заболеваний в действительности у человека?
2. Вам приходит сообщение в ТГ. Бот-классификатор, определяет, нужно ли оно вам, или это спам.
3. Рекомендательная система предлагает вам прочитать учебник по машинному обучению в зависимости от списка учебников, которые вы уже прочитали.

</v-clicks>

---

# Что такое машинное обучение?
<div class="grid grid-cols-[5fr_3fr] gap-5]">
<div>
<br>
  <figure>
    <img src="/What_is_ML_rus.drawio.svg" style="width: 500px !important;">
<!--     <figcaption style="color:#b3b3b3ff; font-size: 11px; position: absolute;">Источник:<br>
      <a href="https://srnghn.medium.com/introduction-to-deep-learning-what-do-i-need-to-know-75794ebc4a62">https://srnghn.medium.com/introduction-to-deep-learning-what-do-i-need-to-know-75794ebc4a62</a>
    </figcaption> -->
  </figure>   
</div>
<div>

### Maшинное обучение находится на перекрестке:
<br>

- Математической статистики
- Теории вероятностей
- Математического анализа
- Линейной алгебры
- ...
- **Предметной области**
</div>
</div>

---

# Maшинное обучение находится на перекрестке
<v-clicks depth="2">

- **Математической статистики и теории вероятности**
  - Оценка неопределенности, представление зашумленных данных

- **Линейной алгебры**
  - Компактное представление линейных преобразований данных
  - Методы уменьшения размерности

- **Других отраслей математики**
  - Теория оптимизации, гарантии сходимости и аппроксимации

- Кроме того требуется **опыт работы в конкретной области**
  - Физика, лингвистика, генетика, компьютерное зрение, FinTech, ...

</v-clicks>

---

# Зачем в машинном обучении нужна математика?
<br>
<v-clicks>

### Предположим, ваша модель показывает $81\%$ точности
<br>

### <span style="color:#FA9370">И что теперь?</span>

* Это хорошо/плохо, полезно/бесполезно?
* Можно ли это улучшить?
* Если да, то до какого предела улучшать?
<br>
<br>

### Статистическая теория дает ответы на эти вопросы
</v-clicks>

---

# Зачем в машинном обучении нужна математика?

### Статистическая теория предоставляет:

<v-clicks depth="2">

* Выбрать:
  * **правильный алгоритм** для решения задачи
  * **лучшие гиперпараметры**
  * стратегии **валидации** (проверки) модели

* Распознавать и устранять **недообучение** и **переобучение**

* **Устранять проблемы** с плохими и неоднозначными результатами

* Оценивать неопределенность прогноза

* **Оптимизировать алгоритмы** и строить эффективный программный код
  * Модели должны быть (экономически) жизнеспособными
</v-clicks>

<v-click>

#### <span style="color:#FA9370">Каждое принимаемое вами решение требует понимания</span>
</v-click>

---

# Что такое машинное обучение?
<br>
<br>
<br>
<br>

## Это фреймворк для<br><br> (статистического) нахождения<br><br> **неизвестных функций** из наблюдений.

---

# Что такое машинное обучение? Пример

### **Цель** - увеличить продажи некоторого продукта в 200 случаях

* У нас есть бюджет на рекламу в телевидении, радио и газетах (признаки)
* Необходимо определить взаимосвязь с бюджетом на рекламу и продажами
* Какой признак сильнее всего влияет на целевую переменную?
<div class="grid grid-cols-[5fr_3fr] gap-5]">
<div>

* Каким образом распределить бюджет,<br>
чтобы повысить продажи?<br>

<figure>
  <img src="/stat_learning_example_1.png" style="width: 470px !important">
</figure> 
</div>
<div>
  <figure>
    <img src="/stat_learning_example_2.png" style="width: 300px !important">
  </figure>   
</div>
</div>

---

# Что такое машинное обучение?

### В общем виде:
<v-clicks depth="2">

* Пусть $X$ будет **матрицей данных** с $N$ наблюдениями (точками, случаями)<br> и $p$ признаками (предикторами, фичами):
$$X = [X_1, X_2, ..., X_p] \in \R^{N \times p}$$

* Пусть $Y$ будет вектором **ответов** с $N$ соответствующими метками: $Y \in \R^N$

* Мы хотим найти **фиксированную**, но **неизвестную** функцию $f$:
$$Y = f(X) + \varepsilon$$

* Где $\varepsilon$ это **независимая** случайная величина со следующими свойствами:
$$\varepsilon \perp\!\!\!\!\perp X_i, ~~ \mathbb{E} \varepsilon = 0, ~~ \mathbb{V} \varepsilon < \infty$$

</v-clicks>

---

# Зачем оценивать $f$?

<v-clicks depth="3">

* Предсказание
  * $\hat{f}$ это неинтерпретируемый **черный ящик**
  * Мы ищем наилучшие **предсказания** для имеющихся $X$
  * Цель - уменьшить **устранимую** ошибку

* Вывод (inference)
  * $\hat{f}$ это интерпретируемый **белый ящик**
  * Мы хотим:
    * понять, насколько **чувствителен** $Y$ к изменениям $X$
    * найти **важные** признаки
    * определить, является ли $f$ **линейной** или более сложной функцией
      * Линейные модели проще интерпретировать

</v-clicks>

---

# Как нам оценить $f$?

* Большинство методов машинного обучения оценивают $\hat{f}$<br> из **обучающих наблюдений** $(x_i^\prime, y_i^\prime) \in \R^{p+1}$
  * $x_i^\prime$ - $i$-й вектор значений признаков

<div>
  <br>
<figure>
  <img src="/data_matrix_2.png" style="width: 600px !important">
</figure>   
</div>

---

# Ландшафт проблем машинного обучения

<div>
<br>
<figure>
  <img src="/ml_problems.png" style="width: 580px !important">
</figure>   
</div>

---

# Обучение с учителем или обучение без учителя

* **Обучение с учителем**: каждое наблюдение сопровождается ответами (метками), $y$
  * Мы хотим соотнести:
    * строки наблюдений, $x_i$, с их предсказаниями, $y_i$<br>
    или<br>
    * столбцы признаков, $X_i$, со столбцом ответов

* **Обучение без учителя**: без ответов (меток)
  * Мы ищем соотношения между
    * столбцами признаков, $X_i$
      * Группируем похожие признаки вместе (PCA, NMF, Gaussian Mixture)
    * строки наблюдений, $x_i$ с $x_j$
      * Группируем похожие наблюдения (kMeans, DBScan, HAC)

---

# Задачи регрессии и классификации

* **Категориальные** переменные принимают значения в $k$ классах (категориях)
  * Если такие переменные **порядковые**, то можно это использовать
* Часто мы можем перейти от одной задачи к другой

<div>
<br>
<figure>
  <img src="/reg_vs_class_rus.drawio.svg" style="width: 770px !important">
</figure>   
</div>

---

# Основные принципы выбора модели

### Итак, существует множество моделей и множество типов проблем, к тому же [бесплатного завтрака не бывает](https://ru.wikipedia.org/wiki/%D0%91%D0%B5%D1%81%D0%BF%D0%BB%D0%B0%D1%82%D0%BD%D1%8B%D1%85_%D0%B7%D0%B0%D0%B2%D1%82%D1%80%D0%B0%D0%BA%D0%BE%D0%B2_%D0%BD%D0%B5_%D0%B1%D1%8B%D0%B2%D0%B0%D0%B5%D1%82).<br><br>

### Так как же выбрать лучшую для нашей конкретной задачи?<br><br>

### Есть несколько ключевых выборов / компромиссов, которые необходимо сделать:<br><br>
* Параметрическая модель или непараметрическая
* Настраиваемая или интерпретируемая модель
  * решение задач предсказания или вывода, соответственно
* Модель с малым смещением или с малой дисперсией?

---

# Параметрические модели

### Используют функции с **конечным** числом параметров

* Шаг 1: **Зафиксируем семейство** параметрических моделей $\mathcal{F}$
  * Также мы определяем размерность пространства параметров
* Шаг 2: **Зафитируем модель** на тренировочных наблюдениях
  * Т.е. оценить параметры модели (с помощью м.н.к., градиентного спуска, ...)
<br>

#### Пример:
* Возьмем **логистическую регрессию** с $p+1$ параметрами<br>
$$\log\bigg(\frac{p(X)}{1 - p(X)}\bigg) = \beta_0 + \beta_1 X$$

* Оценим коэффициенты регрессии $\beta$ с помощью<br> [метода максимального правдоподобия](https://ru.wikipedia.org/wiki/%D0%9C%D0%B5%D1%82%D0%BE%D0%B4_%D0%BC%D0%B0%D0%BA%D1%81%D0%B8%D0%BC%D0%B0%D0%BB%D1%8C%D0%BD%D0%BE%D0%B3%D0%BE_%D0%BF%D1%80%D0%B0%D0%B2%D0%B4%D0%BE%D0%BF%D0%BE%D0%B4%D0%BE%D0%B1%D0%B8%D1%8F): $\ell(\beta_0, \beta_1) = \prod\limits_{i:y_i=1} p(x_i) \prod\limits_{j:y_j=1} (1 - p(x_j))$

---

# Параметрические модели

### Свойства параметрических моделей:

* **Переобученная** модель запоминает шум в обучающих наблюдениях и не может хорошо обобщить новые наблюдения
  * Хорошо работает на обучающих данных, но плохо - на новых (тестовых)

* **Недообученная** модель не может отразить основные взаимосвязи в данных
  * Плохо работает на обучающих и новых данных

* Сложные модели (например, деревья решений или нейронные сети) склонны переобучаться, если их не контролировать и не использовать регуляризацию

---

# Непараметрические модели

* Мы не выбираем семейство функций
* У таких моделей **нет** параметров обучения или их количество **переменное**
  * Исследователю по-прежнему доступны **гиперпараметры** (не обучаются)
<div class="grid grid-cols-[5fr_3fr] gap-9]">
<div>

* Могут производить гладкие функции
  * Можно контролировать их гладкость
</div>
<div>
<br>
<figure>
  <img src="/ISLP_figure_2.6.png" style="width: 420px !important">
</figure>   
</div>
</div>

---

# Непараметрические модели: примеры

* Классификатор k-ближайших соседей (**kNN**)
* Гистограмма, определяющая функцию плотности распределения
* Определение плотности ядра (**KDE**)
* Метод опорных векторов (**SVM**)
* Непараметрическая логистическая регрессия

<div class="grid grid-cols-[5fr_5fr] gap-9]">
<div>
<br>
<figure>
  <img src="/non-param_1.png" style="width: 290px !important">
</figure> 
</div>
<div>
<br>
<figure>
  <img src="/non-param_2.png" style="width: 290px !important">
</figure>   
</div>
</div>

---

# Непараметрические модели и индуктивная предвзятость

### Непараметрические модели кажутся лучшей идеей - почему мы не можем использовать их повсеместно?

* Это потому, что у них все еще есть некоторые предположения относительно данных, или **индуктивная предвзятость**

* В **параметрических** моделях мы делаем **явные** предположения об истинном значении $f$

* В **непараметрических** моделях мы делаем **неявные** предположения

---

# Настраиваемость или интерпретируемость модели

<div>
<figure>
  <img src="/int_vs_flex_rus.drawio.svg" style="width: 630px !important">
</figure>   
</div>

---

# Смещение или дисперсия?

<br>
<div class="grid grid-cols-[4fr_6fr] gap-30">
<div>
  <figure>
    <img src="/bias_vs_variance_1.png" style="width: 390px !important;">
  </figure>
</div>
<div>
  <figure>
    <img src="/bias_vs_variance_2.png" style="width: 410px !important;">
  </figure>
</div>
</div>